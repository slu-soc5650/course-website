[{"authors":null,"categories":null,"content":" Elements of the course are under revision for Spring 2019. Please check the badges on pages in these docs as well as GitHub repositories - if they say Spring 2018 they have not been updated for this semester yet.\n The course docs are designed to provide a single place for accessing resources related to either the course as a whole or to specific lectures. If you find an error or omission, or have a suggestion, please open an issue on GitHub and let me know the details. I want to make sure this is as user-friendly and informative as possible!\nGetting Started These pages are primarily designed to help you get ready to take SOC 4650 or SOC 5650. Their material needs to be completed before the beginning of the semester. The Course Software page also can be used if you decide to set-up the course software on your own computer midway through the semester or have to set-up a new computer.\nFundamentals These reference pages cover materials that don\u0026rsquo;t typically show up in textbooks. They\u0026rsquo;ll be assigned as required readings over the first few weeks of the semester. They also serve as good references as the semester progresses and you find yourself needing reminders about certain basic skills like Markdown or how to format an .Rmd file for this course.\nLectures Each lecture has a page here that includes the primary topics, links to resources, an embedded slide deck, and (sometimes) additional notes about the material covered that day.\nFinal Project This is a landing page with links to final project resources, data, instructions, and a list of the final project due dates.\nTopics There are two indices included in this section - a listing of all of the topic keywords, ArcGIS processes, and R functions that we cover throughout the semester and a listing of R packages used (with links to documentation and resources).\n","date":1543903200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1515132000,"objectID":"4cdd37113783e47641dd300543c94e1b","permalink":"/docs/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/","section":"docs","summary":"Elements of the course are under revision for Spring 2019. Please check the badges on pages in these docs as well as GitHub repositories - if they say Spring 2018 they have not been updated for this semester yet.\n The course docs are designed to provide a single place for accessing resources related to either the course as a whole or to specific lectures. If you find an error or omission, or have a suggestion, please open an issue on GitHub and let me know the details.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-06 \nKey Topics \u0026nbsp; GitHub\nOverview Much of our interaction this semester outside of class will utilize GitHub.com (or just \u0026ldquo;GitHub\u0026rdquo;). GitHub is a web service that is a social network for programmers, developers, data scientists, researchers, and academics. It is also a tool for collaborating on projects, especially projects that involve writing code.\nWe\u0026rsquo;ll use GitHub as an alternative to Blackboard, the course management system that students are typically familiar with. Course materials will be posted there, and GitHub\u0026rsquo;s features will allow you to copy them and keep them updated as changes are made. You\u0026rsquo;ll also use GitHub to submit assignments for grading, and we\u0026rsquo;ll give you feedback and grades via GitHub as well.\nGit Basics Git GitHub is a web application that utilizes Git:\n Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency.\n Essentially, Git is a project-wide system for tracking changes to files. Think of it as Microsoft office\u0026rsquo;s track changes feature on steroids - every change to every file in a directory is tracked. A directory that has tracking enabled with Git is called a repository or \u0026ldquo;repo\u0026rdquo; in Git-lingo.\nYou do no need to host files online to use Git. If you have a project saved locally (say, a doctoral thesis), you could utilize Git to version control that project without ever uploading it to the Internet. However, Git integrates seemlessly with remote repositories. The most well-known host of remote repos is [GitHub.com].\nBeyond \u0026ldquo;repositories\u0026rdquo;, there are a few additional terms that are specific to Git and that are helpful to know:\n Clone: Make an identical copy of a repository on your local hard drive. Commit: Approve any changes you have made to a repository. Sync: For cloned repositories, files that have been changed need to be synced or pushed to GitHub.com after they are committed.  For our purposes, this is just about all you need to know about Git. If you want to learn more, Git\u0026rsquo;s \u0026lsquo;About\u0026rsquo; page is a great place to start.\nGitHub.com GitHub is a web service that can host projects using Git\u0026rsquo;s version tracking. It is widely used by programmers, software developers, data scientists, and academics to host and collaborate projects.\nGitHub is an excellent way to backup files for a project since you can \u0026ldquo;sync\u0026rdquo; changes made to a repository up to GitHub\u0026rsquo;s servers. It is also an excellent way to collaborate on files with colleagues while also using Git\u0026rsquo;s version tracking. Repositories can be either public (like all of the repos for our seminar) or private, which means that only people who have been given access to can view the contents of the repo. Private repos require an upgraded account, which retails for $7/month.\nStudents can get access to GitHub\u0026rsquo;s paid services for free, however, by signing up for a free student account. This will give you access to private repositories for as long as you are a student. GitHub also provides this free upgrade service to educators, which is how our classes have private repositories.\nThe Workflow of Git and GitHub The typical approach to versioning for many students is manual. For a hypothetical class response paper, it might look something like this:\nknitr::include_graphics(\u0026quot;images/gitFlow01.png\u0026quot;)  The author made an initial copy of the paper, and then used a haphazard and inconsistent approach for naming subsequent copies of the paper. We can presume that changes were made in a linear fashion, though it is easy to make changes to, say, First Response Paper 2.doc after First Response Paper 3.doc has been created and edited.\nCommits Instead of saving copies of their hypothetical paper, a student using GitHub could write the paper in a single document, commiting their changes as they progress to take \u0026ldquo;snapshots\u0026rdquo; of their progress. These snapshots contain information on changes the student has made, tracked line-by-line. So, at each point in which a new document would have been created in the typical workflow, a student using GitHub would simply commit their changes:\nknitr::include_graphics(\u0026quot;images/gitFlow02.png\u0026quot;)  Git provides a number of useful features beyond simply tracking changes. Each commit is accompanied a message. These messages must have a short summary that appears on GitHub and can also have a longer description that can be used to describe in detail what changes are being applied with a specific commit:\nknitr::include_graphics(\u0026quot;images/gitFlow03.png\u0026quot;)  Messages, combined with the changes that are tracked, allow users to trace the development of a single document or an entire project overtime:\nknitr::include_graphics(\u0026quot;images/gitFlow04.png\u0026quot;)  This means that, if necessary, the project can also be rolled back to an earlier period. Finally, users can sync their commits with GitHub.com, hosting their changes and their data in a way that protects them against certain types of computer failures and also allowing them to easily share their work with others.\nMore About Repositories Users of GitHub.com adhere to a couple of norms with their repositories that are worth knowing about. Repositories cannot have spaces in their names (much like objects in R), so the naming conventions that we will discuss in relation to R this semester all apply to GitHub as well!\nPublic GitHub repositories also contain (typically) at least three core files:\n A license file - since the data is out there for public consumption, it is important to think about how that data is licensed. The norm among GitHub users has been to use open source licenses, which let others edit and adapt your work. There are a range of licenses that are commonly used on GitHub.\n A README file - this describes the purpose and content of the project.\n A .gitignore file - this stops certain types of files from being swept up by GitHub when a user syncs their files with a server.\n  When you clone your repositories, you will be prompted to save them on your computer. There are a number of ways in which this process can introduce sources for trouble down the road. The principle way that I have seen students run into problems with GitHub is by storing repositories on cloud storage services like Dropbox or Google Drive. In order to avoid any issues, I advise against storing GitHub repositories in an area of your computer that syncs with a cloud service.\nGitHub Issues GitHub has a powerful tool for interaction called Issues. These can be accessed by opening a repository and then clicking on the \u0026ldquo;Issues\u0026rdquo; tab. Issues can be \u0026ldquo;opened\u0026rdquo; by anyone with access to the repository. They allow for a conversation to occur in the form of messages posted within the Issue itself. Files can be attached to Issues, and the messages can contain Markdown formatting. Once the conversation is complete, issues can be marked as \u0026ldquo;closed\u0026rdquo;, which moves them into a secondary view on the website so that they are archived.\nWe\u0026rsquo;ll use issues for both assignment feedback and grading. Please keep up with issues are they appear, and feel free to follow-up with specific questions about your grade or the assignment feedback in the Issue conversation. Once you are satisfied, please mark the issue as closed.\nGitHub Desktop GitHub Desktop is a tool that allows you to easily clone repositories hosted on GitHub, commit changes to them, and then sync those changes up to the website. You can also create new repositories, however this is not task you will have to do this semester. GitHub Desktop is not a fully functional desktop version of GitHub. For our purposes, it is important to note that the Desktop application will not let you easily identify when repositories have been updated by other users, view Wikis associated with repositories, or view Issues.\nLearning More GitHub has a resources page with links to websites that are great for helping you learn more about how Git and GitHub work! The next chapter also has some additional GitHub and Git information.\nOne particularly great tutorial walks you through the command line process for creating and using a git repository. Even if you do not want to use Git via the command line, the tutorial does an excellent job of describing the logic and sequence behind the Git workflow.\n","date":1544076000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544076000,"objectID":"5dff91a970dd2dde0d705a5ecdcde272","permalink":"/docs/git/","publishdate":"2018-12-06T00:00:00-06:00","relpermalink":"/docs/git/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-06 \nKey Topics \u0026nbsp; GitHub\nOverview Much of our interaction this semester outside of class will utilize GitHub.com (or just \u0026ldquo;GitHub\u0026rdquo;). GitHub is a web service that is a social network for programmers, developers, data scientists, researchers, and academics. It is also a tool for collaborating on projects, especially projects that involve writing code.\nWe\u0026rsquo;ll use GitHub as an alternative to Blackboard, the course management system that students are typically familiar with.","tags":null,"title":"Git and GitHub","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-01-05 \nOverview Students have varying experiences learning computational techniques. For some, the math and programming that are the foundation for modern data science techniques come naturally. For others, being introduced to these concepts can be an anxiety producing experience. I am fond the phrase \u0026ldquo;your mileage will vary\u0026rdquo; for describing these differences - no two students have the exact same experience taking a computational methods course. While some of this is specific to this course, the general outlook on approaching data science work that I describe below is hopefully applicable in a far wider arena.\nZen and the Art of Data Analysis One of the biggest challenges with this course can be controlling the anxiety that comes along with learning new skills. R syntax, GIS terms, and Markdown can seem like foreign alphabets at first. Debugging R syntax can be both challenging and a large time suck, in part because you are not yet fluent with this language. Imagine trying to proofread a document written in a language that you only know in a cursory way but where you must find minute inconsistencies like misplaced commas.\nFor this reason, I also think it is worth reminding you that many students in the social sciences struggle with computational methods at first. It is normal to find this challenging and frustrating. I find that students who can recognize when they are beginning to go around in circles are often the most successful at managing the issues that will certainly arise during this course. Recognizing the signs that you are starting to spin your wheels and taking either ten minutes, an hour or two, or a day away from computational coursework is often a much better approach than trying to power through problems.\nData analysis therefore requires a certain mindfulness or what I call \u0026ldquo;habits of mind and habits of method.\u0026rdquo; These mental habits extend past being able to recognize that frustration is setting in. They also include the mental habits needed for Getting and Staying Organized and strategies for Getting Help as you navigate the inevitable errors that come with learning new analytically skills.\nGetting and Staying Organized Doing data science work, and having the space to step away for a day as the last section suggests, requires discipline and organization. Similarly, computational coursework can demanding not just because it is complex but because the courses often have a number of moving pieces that you need to keep track of. Being mindful of this challenge from the beginning, and taking steps to plan for it, is an important part of this course.\nKeeping Track of Where You Are Students who have some system for tracking their work and creating to-do lists are often the most successful in this course, not because they have a fundamentally better grasp on the content but because they simply are more organized. If you have never thought particularly hard about how you manage tasks, now is an excellent time to start doing so. You do not need fancy computer software to accomplish this, though there are an array of possibilities if you do want to use software to keep yourself organized. A legal pad or a notebook can be just as effective as a $50 to-do list manager. The point is, do something!\nI am fond of recommending the Getting Things Done methodology to students as part of thinking more holistically about staying organized. The website Lifehacker posted an excellent introduction to GTD that is a great way to get a sense of how it works and find additional resources for implementing it.\nThe GTD website has a great list of software for those of you looking for a to-do list application. One that isn\u0026rsquo;t listed that I have used for collaborating with my student research team is Trello, a freemium website that allows you to create simple to-do lists. It isn\u0026rsquo;t sophisticated enough for implementing GTD, but it is more than sufficient for managing to-do lists related to this course.\n","date":1543989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515132000,"objectID":"2df115bbe4c2470f1bcd26e88c00c7c6","permalink":"/docs/course-approach/","publishdate":"2018-12-05T00:00:00-06:00","relpermalink":"/docs/course-approach/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-01-05 \nOverview Students have varying experiences learning computational techniques. For some, the math and programming that are the foundation for modern data science techniques come naturally. For others, being introduced to these concepts can be an anxiety producing experience. I am fond the phrase \u0026ldquo;your mileage will vary\u0026rdquo; for describing these differences - no two students have the exact same experience taking a computational methods course.","tags":null,"title":"Approaching Coursework","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nKey Topics \u0026nbsp; R  reprex\nOverview One of the biggest challenges for students first learning tools like R, ArcGIS, and LaTeX is dealing with the inevitable speed-bumps and errors that come along with scientific computing. Remember, first and foremost, that these tools are not consumer software. They do not always \u0026ldquo;just work\u0026rdquo;, to borrow a turn of phrase from Steve Jobs. Learning strategies for navigating issues when the software is most definitely not working is therefore an important part of success.\nOne misconception that I think is important to confront is that data analysts, software engineers, and others who appear to be experts may indeed be very good at what they do, but they are equally skilled at problem solving. This xkcd comic illustrates (a bit sarcastically!) the point:\nknitr::include_graphics(\u0026quot;images/tech_support_cheat_sheet.png\u0026quot;)  Navigating challenges with data science may not be quite as easy following the flowchart above, but there are definitely strategies for working your way through errors and challenges in data science work.\nHelping Yourself As I noted in [Zen and the Art of Data Analysis], a key challenge of data science work is mental. One of the traits I see frequently among students who are confronted with errors is that they stop working and wait for office hours or they immediately ask a question on Slack. Both office hours and Slack are excellent options for getting help, but there are a few strategies you should pursue first.\nBefore you doing anything else, however, take a deep breath and consider taking a break. When you being trying to fix the issue, check the time. I have spent hours trying to fix some code in R or mis-projected data in ArcGIS without success, and I have seen students do the same. Give yourself an hour time limit to try the steps below before you move on to constructing a reproducible example and asking for help from others.\nCheck Spelling With R, the number one cause of errors that I see are misspellings. If objects in the global environment or variable names within a data frame are not spelled correctly (case matters!), you will get an error that an object cannot be found. The same goes for package and function names - they must be spelled 100% correctly.\nCheck Course Resources If the issue is one other students have come across as well, it is likely to be discussed on Slack in the relevant channel. I may have also updated some of the course handouts or the relevant lecture\u0026rsquo;s course webpage with details for how to address the concern. Check both Slack and the webpage for updates before digging deeper. Check the topic index on the relevant course website (GIS topic index) for links to different lectures where concepts or processes were covered.\nCheck Your Process R functions and ArcGIS processes often have specific parameters and requirements. If you have double checked your spelling and are sure (100% sure!) that spelling is not an issue, check to make sure that you have followed all of the requirements of the workflow for the skill you are stuck on. There are two different ways to go about doing this:\n Check the course handouts and lecture slides for the relevant processes. If you cannot remember where the concepts were introduced, check the topic index on the relevant course website (GIS topic index). When I introduce processes, I often skip some (or many!) of the associated arguments and options, so the course materials are often easier to navigate than materials for other sources. Search official documentation sources:  For R, check package documentation files on CRAN. These are linked to in the package index on the relevant course website (GIS package index). You can also use CRAN\u0026rsquo;s website to search for package information. For ArcGIS, check ESRI\u0026rsquo;s official documentation files. Make sure that you are looking at the help files for ArcGIS 10.3! For Git and GitHub, check GitHub\u0026rsquo;s help website. For LaTeX, ShareLaTeX has an excellent set of documentation files on their knowledge base. CTAN, the LaTeX package repository, also contains documentation files for all packages that can be searched.    Use these resources to try and narrow down what might be causing your issue. Be mindful that the root cause of an error may be several steps back in your workflow. Walk back through your process to make sure your initial steps are not the cause of the error.\nCast a Wider Net If none of these resources are sufficient, there are a few other options for seeking out guidance. When you search the following sites, it is often a good idea to search based on the specific error you are getting. Take out any aspects of the error that are specific to you, like a file path in ArcGIS, a file name, or a variable name. One set of options to search are the wealth of web resources that are available for some of the tools we use:\n For R, check out RStudio\u0026rsquo;s cheatsheets and RStudio\u0026rsquo;s community forums. If the package is part of the tidyverse, check the website as well as R for Data Science. Other packages have their own websites as well. For all of these resources, links are provided in the package index on the relevant course website (GIS package index). For LaTeX, there is a LaTeX wikibook with some excellent resources.   Another resource is Stack Exchange, a network of online communities on a variety of topics including:\n Stack Overflow for R, Git, and GitHub - search using tags like [r], [ggplot2], [dplyr], [git], [github], etc. Geographic Information Systems for GIS - search using the [arcgis-desktop] tag TeX for LaTeX  Stack Exchange may have posts that address the issue or question you have. However, the match may only be partial and may require additional modification or tinkering to solve your specific concern. You may spend just as much time trying to get a Stack Exchange solution to work as you would waiting for a response on Slack, so proceed with caution if you decide to go this route.\nFinally, if you have exhausted these other options, a Google search may be effective. This may help you identify GitHub issues, blogs, and other online tutorials that can help address whatever roadblock you have run into. Try searching first with double quotes around the main body of the error message\u0026rsquo;s text. If nothing comes up, try searching without the double quotes. Search strings that include R package names or specific processes in ArcGIS are sometimes helpful for narrowing down a large amount of search results, especially if those results are not specific to the tool you are using. The same warning for Stack Exchange also exists for Google, however. You may find imperfect matches for your problem that take considerably more tinkering to implement.\nSeeking Help with Reproducible Examples If all else fails and the strategies for [Helping Yourself] have not yielded a solution, it is time to ask for help! Before you head to office hours or Slack, you will want to construct a reproducible example.\nWhat is your question? Start with a basic step - narrow down what your question is. Neither \u0026ldquo;I am getting an error\u0026rdquo; or \u0026ldquo;This isn\u0026rsquo;t working\u0026rdquo; are effective questions. What exactly is causing the error? What context does it appear in? To borrow from the examples below, a good question might be:\n I am trying to calculate descriptive statistics for an entire data frame using the mean() function but am getting and error. What might be the cause of the error?\nI am trying to create a thematic choropleth map in ArcGIS, but when I try and select my variable from the dropdown menu in the symbology tab under layer properties, the menu is empty. Why are all of the variables missing?\nI am trying to make my text bold in LaTeX, but the text is not rendering with bold font. I am also getting an error that says \u0026ldquo;Undefined control sequence.\u0026rdquo; What is missing from my document to create bold font?\n Be specific about what your issue is, and then provide a reproducible example that illustrates what you are asking about.\nWhat is a reproducible example? A reproducible example, or reprex, is a term we\u0026rsquo;ll borrow from the R ecosystem. It was coined by Roman François and has been enshrined in the reprex package, which I\u0026rsquo;ll describe below. The goal for a reprex is to strip down the process you have used to the minimal number of steps needed to replicate the error. This means using the fewest steps and data sources possible. Cut out anything that does not directly contribute to causing the error when making your reprex.\nI have often found that the process of making a reprex actually helps isolate the cause of the problem. For instance, it may become clear that a specific step is causing an issue. Even if you are not sure how to fix the problem, having narrowed it down can be immensely helpful. If you can use built-in data in R to create the reprex, or at least example data from the course, that may also help you identify whether the issue is with the process itself or something that is idiosyncratic to the data you are using. Using built-in data from R should be the default for any reprex you create, unless assignment data are the cause of your issue.\nCreating a reprex Creating reproducible examples will differ slightly based on what you are trying to get help on.\nR To create a reprex in R, you will need to install the reprex package. It is part of the tidyverse but it is not installed when the tidyverse package is installed, so you will need to install it separately:\ninstall.packages(\u0026quot;reprex\u0026quot;)  Once you have it loaded (use the library() function), create a minimal example of the necessary functions that get to you to the error you are confronting. Make sure to include the library() functions for all packages your example depends on (except for reprex). Write the example in a .R script file (File \u0026gt; New File \u0026gt; R Script). For example, one might be struggling with calculating the mean of each variable in a data frame:\nlibrary(ggplot2) # assign data to data frame data \u0026lt;- mpg # attempt to calculate mean mean(data)  The last of the three functions above will return this error in your R session:\n\u0026gt; mean(data) [1] NA Warning message: In mean.default(data) : argument is not numeric or logical: returning NA  With the three functions written in a .R script, highlight all seven lines of code (the three functions, both comments, and both white space lines) and copy them to your clipboard (Edit \u0026gt; Copy). Then call the reprex() function. Markdown formatted text that weaves both the functions and their output together will appear in the viewer tab:\nknitr::include_graphics(\u0026quot;images/reprex.png\u0026quot;)  It will also be available on your clipboard so that you can copy and paste it into Slack or another venue that accepts Markdown syntax (like GitHub). If your reprex contains image output, such as a plot or a map, it will be automatically uploaded to imgur and a link will be embedded in your Markdown syntax. For example, say we had a question about the following code:\nlibrary(ggplot2) # assign data to data frame data \u0026lt;- mpg # plot highway mpg ggplot(data = data, mapping = aes(x = hwy)) + geom_histogram()  Once we copy the above code and render it using reprex(), it will return the following output:\nlibrary(ggplot2) # assign data to data frame data \u0026lt;- mpg # plot highway mpg ggplot(data = data, mapping = aes(x = hwy)) + geom_histogram() #\u0026gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ![](https://i.imgur.com/8hiC7od.png)  The ![](hyperlink) syntax will allow an image of your plot to appear below the code.\nThe reprex package website has some great resources, including a basic overview, some reprex do’s and don’ts, and a detailed article introducing the package\u0026rsquo;s functionality.\nArcGIS Creating a reprex in ArcGIS is not as straightforward since there is not a dedicated tool for doing so like there is in R. Reprex creation is complicated by the fact that many steps you will be taking are manual. Nevertheless, it is possible to create a repex. Follow these steps:\n In a new map document, load the minimum number of shapefiles needed to illustrate the issue you are having. Note where the shapefiles are available (in the course data release?) and what their names are. Note what the coordinate system of the data frame is set to. Provide notes for each step that gets you to your question or error. Take a screenshot of the error or the window you have a question about.  For example, a reprex of a question in ArcGIS could look like the following:\n1. I have a single map shapefile open in a new map document. The shapefile is the St. Louis census tracts shapefile from the example data in the course data release. 2. The coordinate system is Missouri State Plane East (Feet) 3. When I right click on the shapefile, I click on Properties and then the Symbology tab 4. Attached is a screenshot of what the symbology tab looks like for these data.  Other Tools For other tools we learn, such as Markdown and GitHub, you want to follow the spirit of the reprex file. Try to provide a detailed walk-through of the steps that you took to get where you are. For Markdown syntax, provide an example of the syntax you are using that recreates the issue or question. For GitHub, provide a screenshot of the relevant error message.\n\u0026ldquo;I don\u0026rsquo;t think I can make a reprex!\u0026rdquo; I am 99.99% sure that you can! In nearly every situation I have seen students in, creating a reprex is possible. Even if the error is idiosyncratic to your computer or your data, you can absolutely clarify the context within which the error appears and minimize the amount of data, code, and other information in your R code or your map document. For the less than 1% of scenarios where a reprex is not possible, the process of writing a question, clarifying the context and steps you took to get there, and producing an example of the error will still make it easier for me to help you.\n\u0026ldquo;Isn\u0026rsquo;t this a lot of work?\u0026rdquo; Well, yes, it does require some extra effort. This effort is almost always worth it, however. In some cases, the time it takes you to produce the repex leads you to the answer on your own, which is part of the problem solving process that this class is designed to foster. Even when this does not happen, making reprex informed inquires is a technique that you will be able to take with you at the end of the semester. Even if you are not working in a technical setting, being able to structure clear, concise questions about a process is a valuable skill!\nFinally, creating a reprex saves you time in the long run. When I get vague questions, it often takes some experimenting on my part to reproduce the error. If you send me a question with a reproducible error, you cut out that experimentation time on my end and I can get right to answering your question. Likewise, students often come to office hours without an example of their issue ready to go and hope that I can conjure in my mind the scenario they are describing. Despite my best efforts, I am usually unable to do so and ask students to reproduce the error during office hours. If you come to office hours with a reprex, we can get to answering your question right away!\nWhere to Seek Help Once you have tried [Helping Yourself] and have gone through the steps outlined in How to Seek Help, it is time to ask your question. There are a number of different places that you can pose questions. The sections below outline these and suggest some ways to make your question most effective.\nInternal Venues Within the confines of the course, the two best places to ask questions are on Slack and during office hours. When asking a question on Slack, please consider doing so in a public channel. This helps others learn from the question that you have. The only course-related questions that are not appropriate for Slack are those that reference specific parts of a problem set or the final project. However, if you are creating reproducible examples, your questions should not be that specific even if they ultimately are about a homework assignment. If you are not sure whether the question is appropriate or not for a public channel, or just would prefer not to ask your question out in the open, feel free to send me a direct message on Slack.\nWhen you pose a question on Slack, it should contain three or four pieces of information:\n The question itself - what are you hoping to get help with? A reproducible example - give as many details as you need to clearly illustrate the question A screenshot or image output that illustrates your reprex What you\u0026rsquo;ve tried - lay out the steps you took to quickly (\u0026ldquo;I\u0026rsquo;ve checked the spelling, gone through the Lecture 03 documents, looked at the dplyr website, and have done a quick Google search.\u0026ldquo;)  Post your reprex as a snippet in Slack by:\n Clicking the plus sign on the left side of the message box Selecting Code or text snippet Filling out the pop-up window  If you are posting a reprex from R, remove the three backticks and the letter r from the first line as well as the three backticks from the bottom line. If you are including an image hyperlink created by the reprex package, remove that from the code snippet and paste it into Slack separately. A good question on Slack should look like this:\nknitr::include_graphics(\u0026quot;images/slackQuestion.png\u0026quot;)  This same general process holds for asking questions in person - come ready with a solid question, a reproducible example, and be ready to pull it up on your computer or a lab computer.\nExternal Venues There are two good places to ask questions external to the course as well. For questions related to RStudio, R Markdown, and the tidyverse, RStudio maintains a web forum called RStudio Community. If you are posting there, you can use reprex() to generate Markdown formatted reprexs.\nAnother place to post questions in on one of the relevant Stack Exchange communities:\n Stack Overflow for R, Git, and GitHub - post using tags like [r], [ggplot2], [dplyr], [git], [github], etc. Geographic Information Systems for GIS - post using the [arcgis-desktop] tag TeX for LaTeX  Before you post, search thoroughly to make sure that your question has not already been answered. Stack Exchange has strong norms about how to post appropriately. You can descriptions of what makes a good post here and here. You can also find a description of what not to ask. If you are going to post on Stack Overflow, the reprex() function can be modified to produce well-formatted output specific to that site by adding the venue argument, as in reprex(venue = \u0026quot;so\u0026quot;).\nOf the two sites, I find RStudio Community to be a friendlier place that is more relaxed than Stack Overflow and its cousins. However, Stack Exchange communities have much larger user bases to draw from.\n","date":1543989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543989600,"objectID":"a4ab682afddcb6d133e7188207f45ddc","permalink":"/docs/getting-help/","publishdate":"2018-12-05T00:00:00-06:00","relpermalink":"/docs/getting-help/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nKey Topics \u0026nbsp; R  reprex\nOverview One of the biggest challenges for students first learning tools like R, ArcGIS, and LaTeX is dealing with the inevitable speed-bumps and errors that come along with scientific computing. Remember, first and foremost, that these tools are not consumer software. They do not always \u0026ldquo;just work\u0026rdquo;, to borrow a turn of phrase from Steve Jobs.","tags":null,"title":"Getting Help","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nOverview This section introduces some of the core concepts that support sociospatial data science works. The title of the chapter takes inspiration from a recent article titled Good enough practices in scientific computing (Wilson et al. 2017). The authors note in their introduction that scientific computing advice can sometimes be both overwhelming and focused on tools that are inaccessible to many analysts. Their goal, and the goal of this text, is to de-mystify the simplest tools that enable researchers to streamline their workflows:\n Our intended audience is researchers who are working alone or with a handful of collaborators on projects lasting a few days to a few months, and who are ready to move beyond emailing themselves a spreadsheet named results-updated-3-revised.xlsx at the end of the workday\u0026hellip;Many of our recommendations are for the benefit of the collaborator every researcher cares about most: their future self.\n I would argue that the skills they describe are useful beyond just a few months. Indeed, most of the skills here can dramatically improve students\u0026rsquo; dissertation experiences:\n Most importantly, these practices make researchers more productive individually by enabling them to get more done in less time and with less pain. They also accelerate research as a whole by making computational work (which increasingly means all work) more reproducible. But progress will not happen by itself. Universities and funding agencies need to support training for researchers in the use of these tools. Such investment will improve confidence in the results of computational work and allow us to make more rapid progress on important research questions.\n While much of what we will talk about in this text is aimed at supporting your work, there are benefits that extend beyond your dissertation or your research projects. These benefits, which include developing sustainable workflows and structuring the way you interact with your own computer, can make everyday computing practices like checking email or organizing files an easier, more structured process.\nReproducibility One of the mantras of this text is an emphasis on reproducibility. The unifying feature of all of the \u0026ldquo;good enough\u0026rdquo; research practices discussed below is that they contribute to a more reproducible research product.\nReproducibility is very much in vogue right now for number of reasons. Assessments of studies in psychology1, for example, have found weaker on average effect sizes and far fewer statistically significant results than the initial studies reported. There have also been high profile instances of falsified research, including research by a graduate student at UCLA. This particular instance of fraud was identified by graduate students intent on replicating the original study.\nAt the same time, there is a recognition that the skills necessary for producing reproducible research are not being fostered in academic disciplines and graduate programs. Thus one of the goals of this course, and this User\u0026rsquo;s Guide in particular, is to help develop a working knowledge of many of these skills.\nOne challenge, however, is that reproducibility does not have a consistent definition. Some researchers use the term to narrowly refer to code that can execute without alteration on a person\u0026rsquo;s computer. Others use it to refer to research designs that can be replicated by other researchers. Still others discuss reproducibility as the ability to obtain a similar set of results or draw similar inferences from identical research designs.\nWhen we talk about reproducibility in this class. We\u0026rsquo;ll be primarily concerned with methods reproducibility:\n the ability to implement, as exactly as possible, the experimental and computational procedures, with the same data and tools, to obtain the same results.2\n Methods reproducibility in statistics means that other analysts have full access to both the original data and the steps used to render those original data into a final research product, such as a set of regression models This is increasingly seen not just a matter of good research methodology, but as a matter of research ethics as well. Being able to be transparent with research decreases the potential for cases like the fraudulent dissertation research conducted by a UCLA graduate student named Michael LaCour. It was the efforts of two Stanford graduate students who wanted to reproduce LaCour\u0026rsquo;s findings that ultimately led to the identification of problematic work.\nFor statistics, methods reproducibility is derived from a number of sources. The first source is the use of computer code for working with data. Rather than making manual changes to tabular data in a spreadsheet application like Microsoft Excel, computer code provides detailed records of each individual alterations. Code can be used execute tasks repeatedly, meaning that errors can be easily fixed if they are discovered an hour, a day, a week, or a month later. During this semester, we\u0026rsquo;ll use R\u0026rsquo;s programming language to execute reproducible data cleaning processes.\nThe second source of reproducibility in statistics is therefore derived from the documentation that we create to accompany our research products. These documents outline where our data originated, what specific variables mean (a codebook), what steps were taken to create specific maps (a research log), and how our data files are organized (a metadictionary).\nOur code can also be used as documentation if it is written using literate programming techniques. In R, these techniques produce well annotated output that \u0026ldquo;weaves\u0026rdquo; together code, output, and narrative text that describes the function of the code and the results of the output.\nThe third and final primary source of reproducibility in statistics is derived from our organizational approach to our work. Statistics projects can require many megabytes of data spread across dozens of data files, scripts, and output files. A disorganized file system can make replicating your work difficult if not impossible. Much of the research practices discussed in the remainder of this section are aimed at supporting one or more of these three major sources of reproducibility.\nThinking in Workflows One way to increase the reproducibility of a project is to approach each and every task with purposeful organization and thoughtfulness. Workflows are the processes that we use to approach a given task. Think of checking your email. You (hopefully!) follow a series of steps when you check your email that help you organize your inbox. In his excellent primer The workflow of data analysis using Stata (2009), Scott Long describes a structured strategy for approaching statistical research. In Long\u0026rsquo;s model, a data analysis project consists of four steps: (a) data cleaning, (b) analysis, \u0026copy; presenting results, and (d) protecting files. This is a useful model to build upon, and one that we will discuss over the course of the semester.\nEven more useful, not just for statistical work but for any process, are the tasks Long lays out for each step in the data analysis workflow:\n Planning Organization Documentation Execution  A good example of the utility of extending this logic to other workflows is with the problem sets. The \u0026ldquo;typical\u0026rdquo; approach students take with homework assignments is to sit down, open up their software, and start with question 1. Using Long\u0026rsquo;s four task approach, a workflow-based strategy to the assignment would involve beginning by reading the assignment through in its entirety to develop a plan for approaching it - think about what techniques and skills are needed for each step. With a plan in place, you can proceed to organizing yourself for the assignment - identifying and obtaining files that you will need, creating dedicated directories for saving assignment data, and getting any necessary software documentation. After pulling together all of these materials, you are ready to move on to documentation - setting up your assignment code and output files, and (later in the course) your research log and meta-dictionary. Once you are set-up, you would then begin to address individual assignment questions as part of the execution task.\nThe goal here is to approach everything you do for research or work with an element of mindfulness and structure about your process. This mental model for approaching research supports the creation of reproducible research products because we approach our work in a routinized, predictable, organized, and efficient manner. Thinking in terms of workflows also encourages a greater awareness of the complexity of tasks, which also helps you plan more accurately for how long a particular task or project will take.\nIn reality, there will be multiple workflows that you find yourself navigating. You will want a structured process not just for approaching a large research project like the final project, but also a process for maintaining notes related to a specific assignment, a process for documenting code, a process for approaching assignments, and even a process for backing your data up. As you go through the text, think about how to best integrate these ideas into your work habits.\nData One of the themes in Good enough practices in scientific computing (Wilson et al. 2017) is an emphasis on data management. One of their core messages is to ``save the raw data\u0026rdquo;. Particularly in GISc work, the raw data can be expansive - dozens of shapefiles, tabular files, and associated metadata. These files often come from disparate sources - city open data sites, the U.S. Census Bureau, state data repositories, and other federal agencies. Moreover, GIS data are often updated over time to reflect on-the-ground changes. Saving the raw data in sociospatial data science work therefore means not only creating a well-organized directory containing all of your original data. It also means logging the source of each file, when it was downloaded, and (if applicable) a permanent web link to your data source. For that reason, we\u0026rsquo;ll give you not just the course data but a read me file and a metadictionary that lists all of the files we\u0026rsquo;ve disseminated to you.\nA second message in the paper is to \u0026ldquo;create the data you wish to see in the world\u0026rdquo;. The authors encourage readers to \u0026ldquo;create the data set you wish you had received.\u0026rdquo; First and foremost, this means using open and not proprietary data formats. For spatial data, ESRI shapefiles are technically proprietary, though their standard is open. This means that other software applications, like R and QGIS can read and in some cases write shapefiles. For sharing spatial data, a better option is the GeoJSON, which is a plain text file format. Tabular data are best stored as CSV files, which is also a plain text file format that can be opened by a wide variety of applications. In contrast, common file formats like Microsoft Excel\u0026rsquo;s XLS and XLSX are proprietary file packages that cannot be read as plain text and are therefore less desirable for storing data.\nPlain Text Along with creating the data we wish to see, Good enough practices in scientific computing (Wilson et al. 2017) repeatedly emphasizes the importance of using plain text files for writing as well as for data. Using plain text file formats, like .txt and .md files, frees us from reliance on proprietary applications that we cannot be sure will exist in ten or twenty years (and are thus threats to reproducible research). They can also be opened on virtually any computer across a variety of operating systems. The authors of the article reference [Markdown] files, which a really just plain-text files containing special characters that can be rendered by websites and other applications. [Markdown], which is discussed later in this text, provides us with the best of both worlds. We can produce outputs with rich text like styling but that is saved in a plain text file container. Writing in a markup language can seem daunting at first, but within a few weeks I have found that most people can start to feel comfortable inserting markup syntax without significant cognitive burden.\nVersion Control One of the key emphases of both Good enough practices in scientific computing (Wilson et al. 2017) and \u0026ldquo;opinionated analysis development\u0026rdquo; is that data science work should be tracked using version control software. This text introduces Git in the [Basic Git] chapter, though there are other options like Subversion and Mercurial. Git is introduced because it has been widely adopted by the R community and because of the robust web tools associated with GitHub.com. Using version control gives us a timeline of our work along with the ability to revert back to previous versions of our files. This creates a \u0026ldquo;chain of evidence\u0026rdquo; for our research process and protects us from irrevocably altering files.\nAs the authors of Good enough practices in scientific computing (Wilson et al. 2017) note, learning version control software can be tricky. There are two chapters later in this text dedicated to Git covering both [Basic Git] and [Advanced Git] techniques. Those chapters also provide links to other resources and tips for using those tools successfully.\n Open Science Collaboration, 2015. Estimating the reproducibility of psychological science. Science, 349(6251), p.aac4716. ^ Goodman, S.N., Fanelli, D. and Ioannidis, J.P., 2016. What does research reproducibility mean?. Science translational medicine, 8(341), pp.341ps12-341ps12. ^   ","date":1543989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543989600,"objectID":"a3c4237dba1195db583886777da6723e","permalink":"/docs/good-enough-practices/","publishdate":"2018-12-05T00:00:00-06:00","relpermalink":"/docs/good-enough-practices/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nOverview This section introduces some of the core concepts that support sociospatial data science works. The title of the chapter takes inspiration from a recent article titled Good enough practices in scientific computing (Wilson et al. 2017). The authors note in their introduction that scientific computing advice can sometimes be both overwhelming and focused on tools that are inaccessible to many analysts.","tags":null,"title":"Good Enough Research Practices","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Full  \u0026nbsp; 2019-01-22 \nKey Topics \u0026nbsp; Analysis development  base \u0026nbsp; Cartography  here \u0026nbsp; Interactive maps  leaflet  magrittr \u0026nbsp; R  readr  sf\nResources \u0026nbsp; View on Syllabus  \u0026nbsp; View on GitHub  \u0026nbsp; View Recording  \u0026nbsp; Exercise - Email  \u0026nbsp; Exercise - Shaw Crime  \u0026nbsp; Functions \nLecture Slides    Leaflet Basics As a way to get to know R and RStudio, we\u0026rsquo;ll be working with the R package leaflet. leaflet is the R implementation of leaflet.js, an open-source Java Script library for building interactive maps. To get started, you\u0026rsquo;ll need to install leaflet and a number of other packages via CRAN:\ninstall.packages(c(\u0026quot;here\u0026quot;, \u0026quot;leaflet\u0026quot;, \u0026quot;sf\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;usethis\u0026quot;))  We can open leaflet and the other packages we\u0026rsquo;ll need with the library() function:\nlibrary(\u0026quot;here\u0026quot;) library(\u0026quot;leaflet\u0026quot;) library(\u0026quot;magrittr\u0026quot;) library(\u0026quot;readr\u0026quot;) library(\u0026quot;sf\u0026quot;)  Get Data To get data quickly for today, you can use the following code snippet in your console:\nusethis::use_course(\u0026quot;https://github.com/slu-soc5650/lecture-01/archive/master.zip\u0026quot;)  A Simple Map leaflet itself is straightforward to get up and running. If we wanted an interactive map with a marker placed on-top of Morrissey Hall, we would use the following script entered into R:\nleaflet() %\u0026gt;% addTiles() %\u0026gt;% addMarkers(lng=-90.237104, lat=38.637547, popup=\u0026quot;Morrissey Hall\u0026quot;)  The leaflet() function creates a map widget, and the addTiles() function adds a basemap to it. By default, OpenStreetMap is used for the basemap. Finally, we use addMarkers() to specify the longitude and latitude of our marker, and we enter in a label that will appear as a pop-up when a user clicks on the marker. lng, lat, and popup are all called \u0026ldquo;arguments\u0026rdquo; - these are used to control how a function operates.\nThe %\u0026gt;% is called the \u0026ldquo;pipe operator\u0026rdquo;, and it is used to chain together functions in what we will call \u0026ldquo;pipelines\u0026rdquo;. This pipeline can be read like a list, with the word then substituted for each instance of %\u0026gt;%:\n First we create a map widget, then we add basemap tiles, then we add a marker at the given longitude and latitude.  The code chunk above produces the following map in RStudio\u0026rsquo;s Viewer tab:\nYou can use the Show in new window icon (a white box with a small arrow facing up and right) to open the map in your web browser.\nChanging the Basemap To alter the basemap, we can use addProviderTiles() in place of addTiles(). I like the CartoDB \u0026ldquo;Positron\u0026rdquo; basemap. To use the Positron basemap, we create a second pipeline:\nleaflet() %\u0026gt;% addProviderTiles(providers$CartoDB.Positron) %\u0026gt;% addMarkers(lng=-90.237104, lat=38.637547, popup=\u0026quot;Morrissey Hall\u0026quot;)  Two things are important to note here. When we load the leaflet package, we have access to a data object called providers. You can use names(providers) to explore it. providers is a vector of items, each of which corresponds to a different basemap. We can select one of those items, CartoDB.Positron, by separating providers from the item name with a dollar sign ($). This is a classic way in which elements of a data set are accessed in R syntax.\nThe second code chunk produces the following map in RStudio\u0026rsquo;s Viewer tab:\nAdding Additional Points The data/sluPlaces.csv file (a .csv file is a type of spreadsheet) contains information on a couple of other places where I find myself regularly on campus. We can read it into R using the readr package (part of the tidyverse):\nsluPlaces \u0026lt;- read_csv(here(\u0026quot;data\u0026quot;, \u0026quot;sluPlaces.csv\u0026quot;))  We read the statement from right to left - the data found at data/sluPlaces.csv is read correctly as .csv data, and the resulting imported data is stored in an object in our global environment named sluPlaces. The here() function helps us write simple, operating system agnostic file paths that will always be relative to where the .Rproj file is stored. We\u0026rsquo;ll talk more about this as the semester progresses.\nWe can explore the data a number of ways, including with the View() (output not shown) function and the str() function:\nstr(sluPlaces)  If we wanted to use View(), it would be implemented like this:\nView(sluPlaces)  When executed in the console, it will produce a spreadsheet-like view within RStudio.\nThe .csv data are tabular data - they contain longitude and latitude data, but they are not projected. This means we are missing the geometric data that locates these longitude and latitude data in space. leaflet can take these spatial references, however, and convert them to usable geometric data. We do so using a very similar process to what we did before:\nleaflet(data = sluPlaces) %\u0026gt;% addProviderTiles(providers$CartoDB.Positron) %\u0026gt;% addMarkers(lng = ~lng, lat = ~lat, popup = ~name)  The data = sluPlaces argument in leaflet() directs R to the appropriate data set to map. We use the tilde (~) to indicate to leaflet that these are variables within sluPlaces.\nThe code chunk produces the following plot:\nReading in Spatial Data For data that have already been converted to geometric data, we use the sf package to read them. The importing process looks similar to what we used with the .csv file. We\u0026rsquo;ll demonstrate this with the violent crime data for Shaw:\nshawViolent \u0026lt;- st_read(here(\u0026quot;data\u0026quot;, \u0026quot;SHAW_Violent_2018.shp\u0026quot;), stringsAsFactors = FALSE)  We\u0026rsquo;ll still use here() to specify the file path, but the function is different now because we need a specialized tool for geometric data. Note that we open the .shp file - this is the primary piece of the family of files that together contain all of the relevant information to locate the Shaw violent crime data in space and describe it. We work with SHAW_Violent_2018.shp, but the other parts must be present as well.\nTo map these data, we no longer need to specify lng and lat because we\u0026rsquo;re using geometric data as well:\nleaflet(data = shawViolent) %\u0026gt;% addProviderTiles(providers$CartoDB.Positron) %\u0026gt;% addMarkers(popup = ~crimeCt)  We use the simplified crime category (crimeCt) for the popup this time.\nThe code chunk produces the following plot:\nFinally, we can make a similar map with all Part 1 crimes:\nshawP1 \u0026lt;- st_read(here(\u0026quot;data\u0026quot;, \u0026quot;SHAW_Part1_2018.shp\u0026quot;), stringsAsFactors = FALSE)  And then we\u0026rsquo;ll map them:\nleaflet(data = shawP1) %\u0026gt;% addProviderTiles(providers$CartoDB.Positron) %\u0026gt;% addMarkers(popup = ~crimeCt)  ","date":1543989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548136800,"objectID":"44385b6d842e4a56bed63692b7ff1610","permalink":"/docs/lecture-01/","publishdate":"2018-12-05T00:00:00-06:00","relpermalink":"/docs/lecture-01/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Full  \u0026nbsp; 2019-01-22 \nKey Topics \u0026nbsp; Analysis development  base \u0026nbsp; Cartography  here \u0026nbsp; Interactive maps  leaflet  magrittr \u0026nbsp; R  readr  sf\nResources \u0026nbsp; View on Syllabus  \u0026nbsp; View on GitHub  \u0026nbsp; View Recording  \u0026nbsp; Exercise - Email  \u0026nbsp; Exercise - Shaw Crime  \u0026nbsp; Functions \nLecture Slides    Leaflet Basics As a way to get to know R and RStudio, we\u0026rsquo;ll be working with the R package leaflet.","tags":null,"title":"Lecture-01 - Course Introduction","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-09 \nKey Topics \u0026nbsp; Analysis development\nOverview The methods introduced in this course are meant to be \u0026ldquo;opinionated\u0026rdquo; - we start from a strong conception about what \u0026ldquo;good\u0026rdquo; geospatial data science looks like. I want to introduce a high level definition of opinionated processes here, and discuss how these ideas might fit into previous coursework you\u0026rsquo;ve taken as well as this one.\nOpinionated Processes The idea of research being opinionated is something I borrow from Hiliary Parker, who has been developing the idea of \u0026ldquo;opinionated analysis development\u0026rdquo;1 over the last several years. Parker argues that opinionated analysis development is a guard against human errors in data analysis that are common but preventable. She emphasizes process repeatedly because, in her view, errors in data analysis are often the result of poor process (and not the individual failures of an analyst).\nFollowing Hilary\u0026rsquo;s lead, we will also make process a cornerstone of our coursework. This emphasis on process is not routine in research methods courses,2 which often treat methods and techniques in isolation and leave much about how they fit together to be learned \u0026ldquo;the hard way\u0026rdquo;. A common experience with statistics coursework is that students will learn the assumptions and requirements of various tests, but not how to fit them together to produce a well-conceptualized analysis. Thus, students working on their first research projects often feel personal responsibility for errors \u0026ldquo;despite not being taught processes that protect against them.\u0026rdquo;3\nParker lays out three core areas for analysis development. Analyses should be:\n reproducible and auditable, accurate, and collaborative.  She also provides a set of opinions and questions about each of these these categories. Projects that are both reproducible and auditable, for example, should be driven by executable analysis scripts with clearly defined dependencies. Projects that are accurate should use modular, tested code and should assertively test data, assumptions, and results. Finally, projects that are collaborative should use version control software for project management, should have the ability to track issues, and should allow for communications that can be archived easily. Many of these same core ideas appear in the article on \u0026ldquo;Good Enough\u0026rdquo; Research Practices.\nOpinionated Tools The tools that we learn in this class have, in large part, been selected because they too are opinionated. Software design is not passive - built into the tools that we select are a particular set of opinions and values about how work should be done. Sometimes these opinions are not strongly stated, however, or there is ambivalence for the experience of the end user. Sometimes these opinions are so strong that they cause problems - Microsoft Excel is famous for actually changing the values of imported data based on the assumptions built in about both data and its users.\nContextualizing These Ideas Each time I teach a research methods course, I have students with a mix of experiences. For some students, all of these concepts and techniques are new and they therefore do not have a strong conception of what it means to do research. For other students, particularly those with research experience, these ideas can directly conflict with how they have been taught in the past and how they work. For everyone, these ideas require a greater mindfulness and attention to detail than they are used to.\nOccasionally, students react strongly to these ideas. For example, these opinions could be interpreted as an indictment of students\u0026rsquo; own processes or seen as a desire to micromanage. Others could see the focus on process as misplaced. After all, as long as the final product looks good, what does it matter how organized the analyst\u0026rsquo;s hard drive is (or isn\u0026rsquo;t)? If you feel like this at any point in the semester, I can sympathize greatly. I remember the frustration I felt the first time I was told that I didn\u0026rsquo;t name variables well and that my code was written in a way that was hard to read.\nWhat I didn\u0026rsquo;t understand at the time, and what I strive to emphasize now, is that process cannot be separated from product. If the process is unclear, undefined, or disorganized, our faith in the final product should be diminished because these flaws limit our ability to judge its accuracy. Thus being \u0026ldquo;right\u0026rdquo; is not solely a judgement of the final results but also how they were obtained. This emphasis on process is inherently more time consuming, slower, and more deliberate than a slapdash approach to data analysis. Our goal is not to conduct data science work in the easiest way, however, it is to conduct it in the most robust way possible.\n Parker H. 2017. \u0026ldquo;Opinionated analysis development.\u0026rdquo; PeerJ Preprints 5:e3210v1 (link) ^ Long, J.S. 2009. The workflow of data analysis using Stata. College Station, TX: Stata Press. ^ Parker 2017, p. 2 ^   ","date":1543989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544335200,"objectID":"7dc0a80664c17448785dbd77f550fdc0","permalink":"/docs/opinionated-tools/","publishdate":"2018-12-05T00:00:00-06:00","relpermalink":"/docs/opinionated-tools/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-09 \nKey Topics \u0026nbsp; Analysis development\nOverview The methods introduced in this course are meant to be \u0026ldquo;opinionated\u0026rdquo; - we start from a strong conception about what \u0026ldquo;good\u0026rdquo; geospatial data science looks like. I want to introduce a high level definition of opinionated processes here, and discuss how these ideas might fit into previous coursework you\u0026rsquo;ve taken as well as this one.","tags":null,"title":"Opinionated Tools and Processes","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nOverview One of the biggest challenges to with doing computational work is that it requires a high degree of organization. Our approaches to file management on computers are often haphazard, with Documents and Downloads folders filled with disorganized files or a Desktop covered in dozens of files. Perhaps this has worked in the past, but that approach (or lack thereof) will fail students in Introduction to Geographic Information Science (SOC 4650\u0026frasl;5650) and Quantitative Analysis: Applied Inferential Statistics (SOC 4930\u0026frasl;5050). Moreover, if left un-checked, it will fail students down the road when a hard drive failure or natural disaster renders their data irrevocably inaccessible. This chapter covers what some of those threats are and ways to manage those risks when conducting computational research.\nThreats To Our Data Each semester that I teach Introduction to GIS and Quantitative Analysis, several things happen. The first thing that happens is that students regularly lose files. The effects of losing files can range from being a minor frustration to a major headache depending on the file in question. Losing files often results in downloading multiple copies of the same data and recreating work. Both of these are wastes of your time. Moreover, files are rarely gone. They are typically just misplaced. This is bad for reproducibility, particularly when you happen across multiple versions of the same file and have to sort out which version is the version you last worked on.\nThe second thing that happens is that students who use thumb drives for data storage lose them. Depending on the timing of this loss, this can again range from being a minor frustration (very early in the semester) to being downright anxiety attack producing (last few weeks of the semester). Recreating an entire semester’s worth of work on the final project is both a tremendous waste of your time and a particularly unpleasant experience.\nFortunately, I have never had a student’s computer hard drive die during the course of the semester. However, I assume that if I teach this course long enough a hard drive failure will indeed occur. The backup provider Backblaze has analyzed their own hard drives and found that about 5% of drives fail within the first year. After four years, a quarter (25%) of drives in their data center fail. Similarly, it is only a matter of time before a student’s computer is stolen along with all of their hard work. A less likely though still very plausible scenario involves the destruction of a student’s belongings (computer and thumb drive included) in a fire, car accident, or natural disaster.\nDespite the likelihood that you will at some-point lose a thumb drive (if not during this semester than sometime down the road) and the near certainty that your computer’s hard drive will eventually fail if a rogue wave does not get it first, few students and faculty take these risks seriously. While you cannot prevent many of these things from happening, I want to suggest to you that you can take some simple steps to sure that when (not if) they happen, you are well prepared to get back to work with minimal disruption.\nCreating a Sustainable File System The first thing that students can do to stave off problems with lost files is to actively and mindfully manage their files. In his excellent document The Plain Person’s Guide to Plain Text Social Science, Kieran Healy describes two important revolutions in computing that are currently taking place. One of them is the advent of mobile touch-screen devices, which he notes\n hide from the user both the workings of the operating system and (especially) the structure of the file system where items are stored and moved around.\n For most users, I would argue that this extends to their laptop or desktop computers as well. I would venture to guess that the majority of my students are used to keeping large numbers of files on their desktops or in an (distressingly) disorganized Documents folder. For research, particularly quantitative research, such an approach to file management is unsustainable. It is difficult to produce any research, let alone work that is reproducible, without an active and mindful approach to file management.\nCreate a Single Course Directory The most successful approach to organizing files is to identify one and only one area that you will store course files in. Having files scattered around you hard drive between you Desktop directory, Downloads, Documents, and a half dozen other places is a recipe for lost files. It can also add complexity to the task of backing these files up. I recommend naming this directory simply based on the course you are enrolled in:\n SOC4650 SOC4930 SOC5050 SOC5650  These names are short, have no punctuation or spaces (which can create conflicts with software), and explicitly connects the directory to this course as opposed to other courses you may take that are also statistics or GIS courses (a good reason to avoid naming the directory Stats or GIS!).\nThis single course directory should reside in one and only one place. Once you have these folders set-up, I want you to an agreement with yourself: files for the course will only be saved within this structure. Do not temporarily save files to the Desktop, for example, intending to move them later. They will be forgotten. Like New Years resolutions, it is easy to say that you will use a file system but difficult to maintain that promise when stress sets in or you are rushed. Do everything you can to maintain your file system.\nStoring the Course Directory Storing this directory inside a sync\u0026rsquo;d directory (like Dropbox or Google Drive) may cause conflicts with your Git repositories. Instead, students for both of my courses should utilize a large sized thumb drive or an external hard drive for data storage (see the \u0026ldquo;Course Onboarding\u0026rdquo; section of the respective course\u0026rsquo;s website for additional details). Having data stored on an external device raises the risk of physical loss, but also makes it easier to move work between different computers. This is particularly challenging for GI Science work, where spatial data sources can be may megabytes in size.\nmacOS users should make sure that the external drive is formatted using the ExFat file system specification so that it is readable both by their operating system and the Windows operating system in the computer lab. If you buy a new drive, you will likely have to re-format it. Directions for doing so are available from Apple.\nApproach Organizing Systematically Within your single course directory, I recommend following a mindful, purposeful approach to organization. This approach begins with having a number of dedicated subfolders within your course directory:\n/SOC5650 /Core-Documents /DataLibrary /DoeAssignments /Lectures /Notes /Readings  Note again how these directories are named - there are no spaces, special characters, and the names are deliberately short but specific. For a directory with two words (e.g. DataLibrary), I use what is known as camelCase to name the file where the second (any any subsequent) words have their first character capitalized. You could also use dash-case (e.g. Core-Documents) or snake_case (e.g. Core_Documents) as a naming strategy. Regardless of which of these approaches you take, try to use it consistently.\nFor both of the courses that I teach, a basic file system will be made available for download onto your external device. See the respective course websites for more information about course data releases. Only the data release for Introduction to Geographic Information Science (SOC 4650\u0026frasl;5650) will contain a DataLibrary directory.\nThe Core-Documents Directory The Core-Documents directory is used for storing the course syllabus, reading list, and a sample schedule for 3600 Morrissey Hall for the semester. You can view it online for both Introduction to GIS and Quanitative Analysis. Once we cover using Git and GitHub in class, you should clone the appropriate Core-Documents repository into your file system. If there are updates, you will want to make sure you pull them down onto your local copy of the repository. You can read ahead in the [Basic Git] chapter for more information on how this works.\nYou will not be able to push changes that you make in this directory to GitHub, and making other changes could cause conflicts. I suggest not making changes inside this repository beyond opening files for reference purposes.\nThe DataLibrary Directory This directory is only applicable to students in Introduction to GIS, whose data release will contain it. It will have copies of most data not disseminated to you as R packages. The data in this directory should be used as needed but not altered (one of the of the [\u0026ldquo;Good Enough\u0026rdquo; Research Practices] from the next chapter).\nThe DoeAssignments Directory Like the Core-Documents repository, this will not be included in the course data release. Once we cover using Git and GitHub in class, you should clone the appropriate Core-Documents repository into your file system. It will also have a different name - your last name instead of \u0026lsquo;Doe\u0026rsquo;. Once you add it, it will contain a number of subdirectories:\n /SOC5650 /DoeAssignments /FinalProject /Labs /Lab-01 ... /Lab-15 /LecturePreps /LP-01 ... /LP-15 /ProblemSets /PS-01 ... /PS-08  The FinalProject directory will not have any subfolders in it. You will be asked to populate it with the appropriate subdirectories (see [Organizing Projects] below). These will be detailed in the final project instructions. The Labs, LecturePreps, and ProblemSets subdirectories have folders dedicated to the individual assignments you\u0026rsquo;ll have to submit over the course of the semester. Like the FinalProject directory, you will need to populate them with the appropriate deliverables. These will be detailed in each assignment\u0026rsquo;s instructions.\nThe Lectures Directory This directory should contain subfolders for each of the sixteen weeks of the course.\n /SOC5650 /Lectures /Lecture-01 ... /Lecture-16  You will need to add these subfolders each week by cloning them from GitHub.com. You will not be able to push changes that you make in these directories to GitHub, and making other changes could cause conflicts. I suggest not making changes inside this repository beyond opening files for reference purposes. If there is something you need to edit, copy it to the appropriate subdirectory of DoeAssignments and make your changes there.\nThe Notes Directory Use this as a home for course notes if you decide to take notes digitally and do not already use notebook software of some kind that organizes notes for you.\nThe Readings Directory Use this as a home for .pdf copies of course readings. I suggest creating subdirectories only for weeks that have readings assigned from outside of the main texts, such as Lecture 01:\n /SOC5650 /Readings /Lecture-01  Organizing Projects Following the excellent article Good enough practices in scientific computing (Wilson et al. 2017), I suggest data science projects should be organized in a specific, standardized way. This approach serves much the same purpose as the previous section on [Creating a Sustainable File System] - work that is well organized is better insured against loss.\nA Sample Project Much as I suggested above that course files reside in one and only one place, projects should be organized similarly (with one important caveat below). What follows is a sample project and then descriptions of each element. More details about each folder (excepting maps) can be found in the article. The project below contains all of key elements of a small geospatial research project:\n /projectName /data rawData.csv rawTracts.shp /doc joinedTracts.md notebook.Rmd notebook.nb.html researchLog.md /maps map.mxd /results joinedTracts.shp map.png /src script.R LICENSE.md projectName.Rproj README.md  Top-Level Files At least two files should be present in each project directory - a README.md and a LICENSE.md. As I noted in the previous chapter, both of these files should be plain-text files. Typically, they are formatted using [Markdown] syntax The README should describe your project, detail any key dependencies or outside data sources that might be required, and provide other important details like how to cite your project and what other online resources might be available.\nThe LICENSE is a key element of open source research. This spells out how others may use (and not use) your work. The excellent guide The Legal Side of Open Source notes:\n Open source is an unusual circumstance\u0026hellip;because the author expects that others will use, modify, and share the work. But because the legal default is still exclusive copyright, you need a license that explicitly states these permissions.\n There are lots of different options for open source licenses, and GitHub\u0026rsquo;s choose a license site does a great job of explaining some of the many options. In the R community, many packages are made available using the MIT or GNU GPLv3 licenses. For written content, presentations, and other non-code works, the Creative Commons Attribution and Attribution-ShareAlike licenses are both common options. For data, the Open Data Commons licenses are not discussed on GitHub\u0026rsquo;s site but are options for data-specific licenses. Finally, large projects sometimes require multiple licenses. If you use a data-specific, code-specific, and/or content-specific mix of licenses, be sure to describe in the README which license applies to which element of of the project. Licensing your projects is another form of protecting your work. If these projects are out in the open, licensing ensures that your work will be used under terms that you are comfortable with.\nIf the project uses R, an R project file (.Rproj) should also be saved in the top-level of the project. This will facilitate the top-level folder being set automatically as the working directory. The working directory is the folder that R will open data from and save data to by default.\nThe data Directory All data sources, with a few exceptions, should be stored here. For instance, in the example above, a tabular data source and a raw shapefile are both used as part of the project. There are, however, a number of exceptions to this. One exception is data that has been packaged in an R package. For example, I have packaged a large set of tables containing historical census data to make them easier to work with. When these are used in projects, I do not save the tables in the data folder. Rather, I make reference to them in the README file and in other project documents.\nA second exception is for large geospatial data libraries, like the data release for my Introduction to GIS. Given the size of these files, it is sometimes impractical to reproduce them multiple times across different projects. Clearly noting that specific files are stored on local libraries available elsewhere in the README file and in other project documents is also an acceptable alternative here.\nThe doc Directory The doc directory should be used for all text documents associated with the project. These might include metadata associated with different project data files, an interactive R notebook, a research log file, and article manuscripts. If needed, subdirectories within doc should be used to keep different files organized. In the example above, joinedTracts.md is the metadata for the similarly named shapefile in the data subdirectory. The notebook files are the interactive R notebook and its associated html output. Finally, the researchLog.md is used for tracking higher level progress over the course of the project.\nThe maps Directory maps is a deviation from Good enough practices in scientific computing (Wilson et al. 2017), which does not envision some of the complexity of working with geospatial data. It should be used for storing the .mxd files from ArcGIS projects or the equivalent QGIS files if that application is being used instead. Illustrator files used for post-processing work should also be stored here if used. Remember that these files should be saved using relative paths to link them to data sources to limit the possibility of conflicts down the road.\nThe results Directory The results directory should contain any data outputs, plots, and map images. These might include intermediate and final versions of data sets as well as shapefiles and GeoJSON files created as part of the analysis process. In the example above, a shapefile combining both of the raw data sources named joinedTracts.shp is saved here along with the exported map image from the map file in the maps subdirectory. Depending on the complexity of the project, subdirectories within results might be necessary.\nThe src Directory For projects that rely on functions not included in packages, for example, or that rely on other pre-made scripts, the src subdirectory should be used for storing script files that are called by notebooks in doc.\nStoring Your Project There are a number of places where work can be deposited. I teach all students in my classes how to use GitHub.com because it integrates directly into version control software, which I see as a critical component of [\u0026ldquo;Good Enough\u0026rdquo; Research Practices]. There are other options, however. For larger projects that may not just be on GitHub (see [Basic Git]) but also utilize a collaborative writing space like Google Docs, the Open Science Framework is an excellent tool. It allows for an even wider set of version control tools to be applied to projects and can be used to organize work that is not easily stored on GitHub, like large number of pdf articles, for which version control is not critical.\nOnce a research project has begun dissemination, repositories like Zenodo and Figshare are designed to make open source data and project materials accessible and citeable. For papers specifically, there are a number of discipline specific archives for pre-prints of papers. Many journals will allow pre-prints to remain freely available even after more formal publication. The original pre-print archive, arXiv, is focused on the STEM sciences and has inspired a number of spinoffs. Many of these are supported by the Center for Open Science, the same organization that operates the Open Science Framework tool described above. For social scientists, SocArXiv is a growing pre-print repository that is part of the Center for Open Science\u0026rsquo;s pre-print network.\nOrganizing Coursework For Introduction to Geographic Information Science (SOC 4650\u0026frasl;5650) and Quantitative Analysis: Applied Inferential Statistics (SOC 4930\u0026frasl;5050), problem sets and the final project should both be organized following the general template above.\nBacking Up Your Data All of the organization in the world cannot prevent a computer hard drive from failing or a natural disaster from destroying your hardware. Similarly, even the best organized of us lose things sometimes or accidentally delete files. Backing up files is therefore a critical piece of not just doing computational work but, in this day and age, it is a requisite skill for owning computer hardware. Every device you own including your phone can and should be backed up. There are a number of different ways to think about backing up your data. The most successful backup strategies will incorporate all of these three elements.\nBootable Backups “Bootable” backups are mirrored images of your entire hard drive, down to temporary files, icons, and system files. With a bootable backup, you can restore your entire computer in the event of a hard drive failure or a corruption of the operating system files. They are named as such because you can plug in the external drive that you are using for this backup and literally boot your computer up from that drive (typically a very slow process).\nThese backups are often made less frequently because they can be resource intensive and it is best not to use your operating system while creating a clone. They are typically made to an external hard drive, which is subject to similar failure rates as the hard drives inside your computer. So bootable drives need to be replaced every few years to maintain their reliability.\nBoth major operating systems come with applications for creating clones of your main hard drive that are bootable, and there are a number of third party applications that provide this service as well.\nIncremental Backups Incremental backups are designed to keep multiple copies of a single file (how often depends on the type of software you use and the settings you select). These can be used to restore an older copy of a file if work is lost or a newer file is corrupted.\nApple’s TimeMachine is a great example of an incremental backup - when kept on, it creates hourly backups of files that have been changed, daily backups for the previous month, and weekly backups for previous months. Once the disk is full, the oldest backups are deleted. Dropbox also provides a similar service, retaining all previous versions of files (and deleted files) for thirty days.\nIncremental backups are typically good options for recovering files that have been recently changed (again, depending on the software you use and the settings you select). Since they run frequently (every time a file is changed or every hour, for example), recent changes tend to get captured. They can be limited in terms of their long-term storage - it may not be possible to recover older versions of a file past a few weeks.\nThey are also not always good solutions for recreating your entire computer since they do not save all necessary program and operating system files, and may be cumbersome to work with if you need to recover a large quantity of files. Like bootable backups, these are typically stored on external hard drives that need to be replaced on a regular basis.\nIn addition to the aforementioned Apple TimeMachine, the Windows OS also comes with a built-in service for creating incremental backups. Dropbox is a good option if you have a small number of files, but you may find the need to upgrade to a paid account if you have a large amount of data.\nCloud Backups Cloud backup services like Backblaze or Crashplan offer comprehensive backup solutions for customers. These plans typically require a monthly subscription fee to maintain access to your backups. While bootable backups protect against hard drive failure and incremental backups protect against data corruption, cloud backups protect against catastrophic events like robberies, fires, and other natural disasters. A fire or a tornado that affect your house may destroy your laptop and any external hard drives you use for backup, but your cloud backup will be unaffected.\nA Workflow for Backups Just as we need a workflow for approaching file management, it is also important to establish a routine for backups. With backups, the most successful workflows are those that require next to no effort on your part. If you primarily use a desktop, this can be as simple as leaving two external hard drives plugged into your computer since most backup software can be set to run automatically. If you have tasks that require you to manually do something (plug an external hard drive into your computer, for instance), create a reminder for yourself on a paper calendar or a digital calendar or to-do list application.\nI gave a presentation on workflows for backing data up as part of the Data Science Seminar series at Saint Louis University. You can easily view the slides from that presentation on Speaker Deck, and you can download the session\u0026rsquo;s materials from GitHub.\n For this course in particular, it is imperative that you backup the data on your flash drive. A number of possibilities exist for accomplishing this:\n Keep a local copy of your flash drive\u0026rsquo;s files on your computer. Keep a .zip archive of your files in a service like Dropbox or Google Drive. (Using a .zip archive will prevent issues with your .git repositories.) Maintain a second flash drive copies of all of your files.  Whatever solution you select, make sure you regularly update your backup. The more often you keep your backup archive updated, the less stressful and disruptive losing your drive will be. This will likely be a manual task, so follow the guidance above about creating a repeating calendar event or to-do list task reminder.\n","date":1543989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543989600,"objectID":"9d53296c4e903c68c0e0cda80faf7db5","permalink":"/docs/protecting-work/","publishdate":"2018-12-05T00:00:00-06:00","relpermalink":"/docs/protecting-work/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nOverview One of the biggest challenges to with doing computational work is that it requires a high degree of organization. Our approaches to file management on computers are often haphazard, with Documents and Downloads folders filled with disorganized files or a Desktop covered in dozens of files. Perhaps this has worked in the past, but that approach (or lack thereof) will fail students in Introduction to Geographic Information Science (SOC 4650\u0026frasl;5650) and Quantitative Analysis: Applied Inferential Statistics (SOC 4930\u0026frasl;5050).","tags":null,"title":"Protecting Your Work","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Full  \u0026nbsp; 2018-01-05 \nResources Onboarding Checklist \nOverview Before you begin the semester, there are a number of things that you should do to help set yourself up for success. All of the applicable sections below should be completed before our first class on January 14th. Before you do anything else, though, you should read through the Syllabus. Make sure you have a good sense of what is required for the course. If you have questions, bring them to the first day of class!\nAccount Signups Get Started with the Discussion Board Discourse is an open source forum platform that we will be using this semester to stay in touch and host virutal office hours. You should receive an email with registration information, and the site can be found here. Once you receive the invitation and accept, you can update your profile by clicking on the profile icon in the upper right-hand corner and selecting the gear icon:\nAt a minimum, please fill out the Name field under Account with your preferred first and last name!\nGet Started with GitHub The service that is hosting this website is called GitHub. GitHub is used by programmers, data scientists, and researchers for hosting computer code, data, and project materials (like websites). We will be using GitHub extensively this semester. You will need a free account, which you can sign up for one from GitHub\u0026rsquo;s homepage. If you already have a GitHub account, you do not need a new one.\nOnce you have a GitHub user name, send Chris a direct message via our discussion board with it so that you can be added to the SOC 4650 \u0026amp; SOC 5650 organization. Your direct message inbox can be found by clicking on the profile icon in the upper right-hand corner and selecting the envelope icon:\nChris\u0026rsquo;s username on the discussion board is chris.prener.\nAfter you have been added to the organization, you should find your assignments repository and check the Issues tab. There should be an open Issue describing how feedback will be disseminated this semester. Please read it and then close the issue so that we know you\u0026rsquo;ve seen it.\nCourse Software There are two options for accessing the course software, and some instructions for how install it. Please read through these options carefully and make the decision that is best for you.\nOptions for Accessing Software One option is to rely on the computers in our classroom, and - lucky you(!) - you get 24-hour access to Morrissey Hall for the semester. If you decide to go this route, you can go right to the course software page to continue setting up your computer - you\u0026rsquo;ll need to install just the specific R packages and GitHub Desktop. Details on the extent of setup required will be posted there since it is subject to change. Make sure you know how to use Windows File Explorer, especially if you are a regular macOS user.\nAnother option for accessing the software is to use your own computer. If you decide to go this route, please read the next subsection on computer prep, and then head over to the course software page to continue setting up your computer. As long as you have a relatively new computer (within the last few years), you should have no problem using any of the applications for this class.\nComputer Prep If you are using your own computer, you should do the following before proceeding:\n Make sure your operating system is up-to-date. If you are able, I would also recommend upgrading your computer to the most recent release of its operating system that the computer can run.\n On macOS, you can do this through the App Store Both Windows 7 and Windows 10 have system update tools.  We\u0026rsquo;ll be sharing computer files throughout the semester, so you should ensure that you have functioning anti-virus software and that it is up-to-date. You can get Symantec EndPoint Protection anti-virus software for free from SLU. Go to \u0026ldquo;ITS Software Downloads\u0026rdquo; under \u0026ldquo;Tools\u0026rdquo; on mySLU.\n You\u0026rsquo;ll also need to download files, so you\u0026rsquo;ll need to make sure you have at least fifty gigabytes free on your hard drive if you are installing ArcGIS Pro and at least twenty gigabytes free if you are not. If you\u0026rsquo;re not sure how to check this, here are some instructions for Windows and macOS.\n Options for de-cluttering include deleting files that are no longer needed, moving files to an external device, moving files to a cloud storage system, or upgrading the internal hard drive (may not be possible for macOS users and some Windows users).  Make sure you know how to access your computer\u0026rsquo;s file management system.\n On macOS, this means being comfortable with Finder.app for finding folders, making new ones, and opening files. Here are some tips for using Finder on recent versions of macOS. On Windows, this means being comfortable with Windows File Explorer for finding folders, making new ones, and opening files. Here are some tips for using File Explorer on Windows 7 or Windows 10.  Head over to the course software page to continue setting up your computer.\n  Get Access to Books There are a number of different books required for this course. Each book has been selected to correspond with one or more of the course objectives. Please purchase copies of the first three books and decide if you would like a physical copy of the fourth:\n Brewer, Cynthia. 2015. Designing better Maps: A Guide for GIS users. Redlands, CA: ESRI Press. Gorr, Wilpen and Kristen Kurland. 2017. GIS Tutorial 1 for ArcGIS Pro. Redlands, CA: ESRI Press. Wickham, Hadley and Garrett Grolemund. 2016. R for data science. Sebastopol, CA: O’Reilly. Webbook Available.  All of the books are available in the bookstore. They can also be ordered online. If you would rather use e-books, those are acceptable for this course as well. The Reading List includes the assigned readings for both the web and print versions of Wickham and Grolemund\u0026rsquo;s R for data science (2016), and you are free to choose either version.\nOther Materials The other item to optionally purchase is a 1.5\u0026rdquo; three-ring binder. While all course materials are available online, they are often easier to use if they are printed. Everyone will get handouts the first week so you can decide if you want to continue receiving hardcopies beyond the first lecture, or if you\u0026rsquo;d prefer to only have the digital copies. If you do opt-in to receiving the hardcopies, a binder will help keep things organized.\nAdministrative Tasks All students should complete the Student Information Sheet, which gives me some info about you and gives you the chance to let me know about any initial concerns you might have. It also contains a syllabus agreement, which confirms that you have read the Syllabus and understand the course policies.\nCoursework There are three pieces of coursework that you should complete:\n You should view two videos posted on the Course Preview page and check out the interactive map discussed in the first video. You should complete the assigned reading (and if you want, the optional ones too) listed in the Syllabus. You should complete Lecture-01 Entry Ticket, which asks a few short questions about the videos and interactive map. You should complete the assigned readings for Lecture-01, which are listed in the Syllabus. Come to class stoked to make your first maps!  ","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515132000,"objectID":"b861d0ca1a691ef3c164ec8ee7d0680b","permalink":"/docs/course-onboarding/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/course-onboarding/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Full  \u0026nbsp; 2018-01-05 \nResources Onboarding Checklist \nOverview Before you begin the semester, there are a number of things that you should do to help set yourself up for success. All of the applicable sections below should be completed before our first class on January 14th. Before you do anything else, though, you should read through the Syllabus. Make sure you have a good sense of what is required for the course.","tags":null,"title":"Course Onboarding","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Full  \u0026nbsp; 2018-01-05 \nKey Topics \u0026nbsp; Analysis development \u0026nbsp; Interactive maps \u0026nbsp; Open data \u0026nbsp; Reproducibility\nOpen Data and GIS in Los Angeles One of the course learning outcomes is titled \u0026ldquo;GISc and Public Policy\u0026rdquo;. Much of the data that we will use this semester is available to us because governmental agencies at the Federal, state, and local levels have published it and made it accessible. We call the movement to make as much data available as possible \u0026ldquo;open data\u0026rdquo;.\nDifferent governments have embraced the open data movement to varying degrees, and the video below discusses Los Angeles\u0026rsquo; integration of open data and GIS. It is a 9 minute talk given by L.A.\u0026rsquo;s former Chief Data Officer Lilian P. Coral. The talk was part of a conference organized by ESRI, the makers of ArcGIS.\n    Once you\u0026rsquo;ve watched the video, check out the web application featured in the video that visualizes pedestrian and cyclist injuries in Los Angeles. You can also visit L.A.\u0026rsquo;s open data website called GeoHub.\nAnalysis Development Making a produce like L.A.\u0026rsquo;s visualization of pedestrian and cyclist injuries is a complicated effort. Data must be obtained from various sources, modified (a process we call \u0026ldquo;data wrangling\u0026rdquo; or \u0026ldquo;data cleaning\u0026rdquo;), and then linked with map coordinates. Once it is ready to be mapped, the web application must be designed and created. We\u0026rsquo;ll call this large-scale process a \u0026ldquo;workflow\u0026rdquo; this semester.\nThe workflow that we\u0026rsquo;ll use is opinionated - there is a strong premise that underlies the workflow about the ways in which spatial data (and data more generally) should be obtained, stored, modified, and mapped. Hilary Parker is a data scientist at Stichfix and also runs a data science podcast called Not So Standard Deviations. She has been speaking recently about an idea called opinionated analysis development. The video linked to below is a 25 minute talk she gave on this idea last year, and she now has a draft paper out on the topic as well. Our workflow for this semester is closely linked to the ideas she discusses in this talk.\n\n Many (but not all of you) will have experienced some parts of these processes before. Perhaps you\u0026rsquo;ve used Microsoft Excel to organize some information or used SPSS to analyze some quantitative data. We won\u0026rsquo;t be using those tools. Instead, this course will emphasize the use of other tools that support reproducible, accurate, and collaborative data analysis. Throughout the semester, we\u0026rsquo;ll discuss why these tools are important and the advantages they have over other products that are out there. Inspired by Hilary\u0026rsquo;s idea of opinionated analysis development, our goal each week will be to focus on the processes that can be used to increase the reproducibility and accuracy of our geospatial work.\nSome of these processes, like using RMarkdown, are introduced in the introductory \u0026ldquo;chapter\u0026rdquo; (it is quite short!) to Duke University sociologist Kieran Healy\u0026rsquo;s primer The Plain Person\u0026rsquo;s Guide to Plain Text Social Science. This is the one required reading for the entry ticket (though there are several optional ones listed on the syllabus.\nLecture-01 Entry Ticket The entry ticket for the first lecture asks three follow-up questions about these videos and L.A.\u0026rsquo;s interactive website. Please answer these questions and submit them before class on January 14th. Answers must be submitted through Google Forms and each response should be three to four sentences in length. The questions are provided here for reference:\n Briefly describe how the City of Los Angeles uses data and mapping to inform how they deliver city services. After viewing the interactive map showing pedestrian and cyclist injuries, describe what you thought of the map. Some example considerations could include: was it easy to read? to navigate? did you like the colors? was it missing relevant data? In your own words, what are the key aspects of opinionated analysis development? What are some of the advantages of using plain text for data analysis?  The entry ticket also asks for an update on your course onboarding process.\n","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515132000,"objectID":"f5d8021a03a81b574899ba6dff3b2e4f","permalink":"/docs/course-preview/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/course-preview/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Full  \u0026nbsp; 2018-01-05 \nKey Topics \u0026nbsp; Analysis development \u0026nbsp; Interactive maps \u0026nbsp; Open data \u0026nbsp; Reproducibility\nOpen Data and GIS in Los Angeles One of the course learning outcomes is titled \u0026ldquo;GISc and Public Policy\u0026rdquo;. Much of the data that we will use this semester is available to us because governmental agencies at the Federal, state, and local levels have published it and made it accessible.","tags":null,"title":"Course Preview","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-04 \nOverview This course is built primarily around a set of four software applications - ArcGIS Pro, the programming language R, the graphical user interface for R called RStudio, and GitHub Desktop. As I noted on the course onboarding page, there are two choices for accessing software. Please read through the course onboarding page page carefully and make the decisions you think are best for you - either using your own computer or using a lab computer. Feel free to shoot me an email if you have questions about which approach is best.\nArcGIS Pro ArcGIS Pro is installed in the GIS lab.\n I am able to provide licenses for ArcGIS Pro to students who are interested in obtaining them. If you would like a license, please check the system requirements first. If your computer meets the minimum requirements, email me for a license. Then:\n Visit ESRI\u0026rsquo;s education edition website to begin the process of activating and downloading your ArcGIS Pro Student Trial software. Log in using your Existing ESRI account (the same one you were given during the course onboarding process). Enter the license code and click Activate ArcGIS. Click the button for the ArcGIS for Desktop software version being activated - the latest version of ArcGIS Pro. If necessary, download the ArcGIS Uninstall Utility and uninstall previous versions of ArcGIS Desktop or ArcGIS Pro. Run the executable file that you downloaded to install ArcGIS Pro.  Spatial Libraries These libraries are installed in the GIS lab and need to be installed only if you are using R on your personal computer.\n There are three open-source spatial libraries that we will indirectly use this semester - GDAL, GEOS, and PROJ.4. They\u0026rsquo;ll be used by the R package sf.\nWindows To install the libraries on Windows, you need to have RTools installed. RTools is a suite of tools for building packages on Windows, and it will allow sf to install a number of spatial data libraries that it requires to read and process shapefiles. These tools require administrative rights, so you may have to enter your password.\nmacOS Users on macOS will have to install the spatial data libraries on their own. An omnibus installer is available from the Kyng Chaos website - you\u0026rsquo;ll want to download and run the GDAL 2.2 Complete installer.\nR Installing Base R Base R is installed in the GIS lab.\n You can download R from its website. Choose \u0026ldquo;Download R for (Mac) OS X\u0026rdquo; or \u0026ldquo;Download R for Windows\u0026rdquo;. Windows users should look for text that says \u0026ldquo;install R for the first time\u0026rdquo; and click the base to the left of that text. Both macOS and Windows users should install R version 3.5.1, known as \u0026ldquo;Feather Spray\u0026rdquo;.\nIf you already have R installed, please make sure you have the latest version. You can upgrade it using the same process for a new installation.\nInstalling R Packages R packages will need be installed both in the lab and on personal computers. Check back on January 13th, 2018 for details.\n RStudio RStudio is installed in the GIS lab.\n RStudio is a graphical user interface for R that will make learning the language and using it much, much easier. You should download the free version of RStudio from their website. Choose the appropriate installer for your platform. Make sure R is already installed before installing RStudio.\nIf you already have RStudio installed, please make sure you have the latest version. You can upgrade it using the same process for a new installation.\nGitHub Desktop GitHub Desktop will need be installed both in the lab and on personal computers.\n In addition to the applications above, everyone will need a local installation of GitHub Desktop, which is a graphical user interface for accessing Git and GitHub.com. It can be downloaded for free from the application\u0026rsquo;s website. You will need to download and run the installer. Once it is complete, you will need to login to the application with your GitHub.com username and password.\nIf you already have GitHub Desktop installed, you should check to make sure you are running the latest version of GitHub Desktop. If you need to update GitHub Desktop, you should also download.\nOther Applications You can download mobile apps for our forum software, Discourse, for both iOS and Android devices.\n","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515132000,"objectID":"4d35c06a94fe58298d2af432933711bc","permalink":"/docs/course-software/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/course-software/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-04 \nOverview This course is built primarily around a set of four software applications - ArcGIS Pro, the programming language R, the graphical user interface for R called RStudio, and GitHub Desktop. As I noted on the course onboarding page, there are two choices for accessing software. Please read through the course onboarding page page carefully and make the decisions you think are best for you - either using your own computer or using a lab computer.","tags":null,"title":"Course Software","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nKey Topics  knitr \u0026nbsp; Markdown \u0026nbsp; R \u0026nbsp; Reproducibility  rmarkdown \u0026nbsp; RStudio  testDriveR\nResources RMarkdown Cheatsheet \nOverview This document assumes you are already comfortable with the content in the Writing in Markdown doc.\n Literate Programming RMarkdown Basics Assignment Layout Code Chunks Enviornment Considerations Working Directory Considerations ","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543903200,"objectID":"93f1532b2946c6c12b03f94028ad2d11","permalink":"/docs/rmarkdown/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/rmarkdown/","section":"docs","summary":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nKey Topics  knitr \u0026nbsp; Markdown \u0026nbsp; R \u0026nbsp; Reproducibility  rmarkdown \u0026nbsp; RStudio  testDriveR\nResources RMarkdown Cheatsheet \nOverview This document assumes you are already comfortable with the content in the Writing in Markdown doc.\n Literate Programming RMarkdown Basics Assignment Layout Code Chunks Enviornment Considerations Working Directory Considerations ","tags":null,"title":"Creating RMarkdown Documents","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-04 \n","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543903200,"objectID":"8f96ecb4274cba6c43d73d7febd2456f","permalink":"/docs/project/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/project/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-04","tags":null,"title":"Final Project","type":"docs"},{"authors":null,"categories":null,"content":" Overview A-D  Analysis development (Fundamentals Articles [a, b, c], Course Preview, Lecture-01)  E-H I-L  Interactive maps (Course Preview)  M-P  Open data (Course Preview)  Q-T  Reproducibility (Course Preview)  U-Z ","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543903200,"objectID":"dc489ba7ffd6f1486d9003568782c4d6","permalink":"/docs/topic-index/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/topic-index/","section":"docs","summary":" Overview A-D  Analysis development (Fundamentals Articles [a, b, c], Course Preview, Lecture-01)  E-H I-L  Interactive maps (Course Preview)  M-P  Open data (Course Preview)  Q-T  Reproducibility (Course Preview)  U-Z ","tags":null,"title":"Topic Index","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nKey Topics \u0026nbsp; GitHub \u0026nbsp; Markdown\nResources GitHub Mastering Markdown  RMarkdown Reference Guide \nBasics Markdown is a simple markup language. Markup languages are used to give computer programs directions on how particular blocks of text should be processed. Markdown was developed in 2004 by writer and developer John Gruber. Gruber describes Markdown on his website:\n Markdown is intended to be as easy-to-read and easy-to-write as is feasible.\nReadability, however, is emphasized above all else. A Markdown-formatted document should be publishable as-is, as plain text, without looking like it’s been marked up with tags or formatting instructions. While Markdown’s syntax has been influenced by several existing text-to-HTML filters — including Setext, atx, Textile, reStructuredText, Grutatext, and EtText — the single biggest source of inspiration for Markdown’s syntax is the format of plain text email.\nTo this end, Markdown’s syntax is comprised entirely of punctuation characters, which punctuation characters have been carefully chosen so as to look like what they mean. E.g., asterisks around a word actually look like emphasis. Markdown lists look like, well, lists. Even blockquotes look like quoted passages of text, assuming you’ve ever used email\u0026hellip;\n\u0026hellip;Markdown’s syntax is intended for one purpose: to be used as a format for writing for the web. Markdown is utilized to varying degrees by many of the data science tools we\u0026rsquo;ll use in both courses, including RStudio, GitHub, and Slack. In all three applications, Markdown provides a straightforward way to format and stylize plain text files. Markdown therefore gives us the best of two worlds - text files can be organized and formatted as in WYSIWYG editors like Microsoft Word, but they remain plain text files that are accessible in a variety of computing environments and do not depend on proprietary applications.\n Markdown\u0026rsquo;s simplicity is sometimes also identified as a weakness - it lacks the full fledged control of html or LaTeX, for example. However, for research documentation, the bells, whistles, and fine-grained control of something like LaTeX are unnecessary. Long-term portability is a far more important characteristic, and Markdown excels in this area.\nMarkdown files are really just plain-text files, which are usually identified as .txt files. However, when they contain Markdown syntax, we want to name them as .md files. Most applications will continue to recognize .md files as plain-text files. However, certain desktop applications like RStudio and some websites like GitHub.com recognize the .md file extension and will \u0026ldquo;render\u0026rdquo; the Markdown syntax into formatted output. When you create Markdown files in an application like RStudio, make sure to save them with the .md file extension!\nDocument Organization There are two principle means for organizing Markdown documents - headings of varying size and paragraph breaks.\nHeadings Markdown contains six heading levels. Headings are identified with # symbols and a space that separates them from from the heading text.\nInput:\n# This is the largest heading ## This is the second largest heading ### This is the third largest heading #### This is the fourth largest heading #### This is the second smallest heading ###### This is the smallest heading  Output:\nNew Paragraphs Leave a blank line between two paragraphs to create a break.\nInput:\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quam pellentesque nec nam aliquam sem et tortor consequat. Auctor urna nunc id cursus metus. Eleifend mi in nulla posuere. Facilisis sed odio morbi quis. Nibh nisl condimentum id venenatis. Lectus nulla at volutpat diam ut venenatis. Pretium lectus quam id leo in vitae. Neque vitae tempus quam pellentesque nec nam aliquam. Curabitur gravida arcu ac tortor. Arcu risus quis varius quam quisque id diam. Viverra aliquet eget sit amet tellus cras adipiscing. Tellus molestie nunc non blandit massa enim nec. Tempus imperdiet nulla malesuada pellentesque elit eget. Non blandit massa enim nec. Sed risus pretium quam vulputate dignissim suspendisse in est ante.  Output:\nWorking with Text Markdown provides a number of tools for working with and stylizing text. These include options for bold and italicized text, adding code blocks, quoting text, and creating bulleted and enumerated lists.\nStyling Text Text can be styled using bold and italics To create italicized text, wrap your text with a single asterisk *. To create bold text, wrap your text with double asterisks **.\nInput:\n*This is an italicized sentence.* **This is a bolded sentence.**  Output:\nQuoting Text Quoting text (which I have used above to illustrate examples) is done with a greater then symbol (\u0026gt;).\nInput:\n\u0026gt; This is quoted text.  Quoting Code In-Line Code There are two types of code quotes in Markdown. In-line quotes, which are included in a sentence, are wrapped in single backticks:\nInput:\nThe `stlLead` data contains a variable named `totalPop`.  Output:\nCode Blocks To include code blocks, which are better for including the full syntax of particular commands and their output, use triple backticks:\nInput:\n```r \u0026gt; summary(stlLead$totalPop) Min. 1st Qu. Median Mean 3rd Qu. Max. 620 2025 2912 2999 3784 7069 ```  Output:\nNote how the letter \u0026lsquo;r\u0026rsquo; is written after the first set of triple backticks. This is an indicator for GitHub that the code is written in R\u0026rsquo;s programming language. By including this, GitHub can apply some syntax highlighting to your files. This makes them easier to read.\nLinks In Markdown, adding hyperlinks is a two step process. The text that you want to have hyperlinked is written first and is wrapped in brackets []. After this, you include the URL wrapped in parentheses (). This is an example of including in-line hyperlinks:\nInput:\nThe [Sociospatial Data Science book](http://chris-prener.github.io/SSDSBook/) is hosted using the service [GitHub](https://github.com).  Output:\nEmbedding Images Images can be embedded in Markdown documents with syntax that is nearly identical to how [Links] were inserted, except that text in the brackets can be omitted. You will add an ! to the beginning of the syntax, and use a URL to an image in the link:\nInput:\n![](http://slu-soc5650.github.io/images/logo.png)  Output:\nYou can replace the URL to an image with a path within a repository organized as suggested in [Organizing Projects] - ![](results/map1.png). The path can be as long as necessary if there are additional directories - ![](results/maps/firstDraft/map1.png).\nLists Bulleted Lists Bulleted lists are indicated in Markdown using the dash - or a single asterisk *:\nInput:\n- mean - median - mode * variance * standard deviation  Output:\nEnumerated Lists Enumerated lists are created by preceding each line with the appropriate number:\nInput:\n1. calculate the mean 2. calculate the variance 3. calculate the standard deviation  Output:\nNested Lists You can create more complex lists by preceding a line with four single spaces. You can also combine bulleted and enumerated lists when using this approach.\nInput:\n1. create a basemap * add street centerlines and the city boundary * use a light hue for the centerline 2. add points for incidents * use red points for fire incidents * use blue points for EMS incidents  Output:\nGitHub Markdown Markdown\u0026rsquo;s original syntax has been augmented numerous times since it was first released. Users sometimes call these different \u0026ldquo;flavors\u0026rdquo; of Markdown. One key flavor of Markdown to be familiar with is GitHub Markdown, which adds a number of additional syntax features to the base syntax discussed in the previous two sections.\nStyling Text Strikethrough text can be useful for indicating that a particular comment or piece of information is no longer relevant while also preserving that text in the document. Strikethrough text can be created by wrapping your text with two tildes ~~ ~~:\nInput:\n~~This is a sentence with strikethrough text.~~  Output:\nSimple Tables Tables can be created using a combination of pipe (|) and dash (-) characters. The dashes are used to separate the header row from the data rows, and there must be at least three dashes per column. The spacing is not required, mis-aligned text in the rows should not prevent the table from rendering nicely. However, I do think that well spaced tables are easier to edit down the road.\nInput:\n| `id` | `name` | `value` | | ---- | ------ | ------- | | 1 | ham | 23 | | 2 | eggs | 18 | | 3 | spam | 6 |  Output:\nTask Lists If you want to create task lists on GitHub, you can include brackets separated by a space before each list item [ ]. Completed tasks include an x in place of the space [x]. These task lists are interactive - when published on GitHub in Issues for instance, you can click on the resulting checkboxes to toggle them between complete / incomplete.\nInput:\n1. [x] calculate the mean 2. [ ] calculate the variance 3. [ ] calculate the standard deviation  Output in Static Markdown Doc:\nOutput in Issue or Pull Request:\nMentioning Other GitHub Users If you want to mention me or one of your classmates in a comment, include the @ symbol before their username. Once the document is uploaded to GitHub, the username will render as a hyperlink and the user will be alerted.\nInput:\nHey @chris-prener, thanks for the feedback. I made the changes to lines 40 and 41.  Output:\n","date":1543903200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543903200,"objectID":"2839b17bfaf78da73982bda2f3c1f08d","permalink":"/docs/markdown/","publishdate":"2018-12-04T00:00:00-06:00","relpermalink":"/docs/markdown/","section":"docs","summary":"Meta \u0026nbsp; Spring 2019  \u0026nbsp; Draft  \u0026nbsp; 2018-12-05 \nKey Topics \u0026nbsp; GitHub \u0026nbsp; Markdown\nResources GitHub Mastering Markdown  RMarkdown Reference Guide \nBasics Markdown is a simple markup language. Markup languages are used to give computer programs directions on how particular blocks of text should be processed. Markdown was developed in 2004 by writer and developer John Gruber. Gruber describes Markdown on his website:\n Markdown is intended to be as easy-to-read and easy-to-write as is feasible.","tags":null,"title":"Writing in Markdown","type":"docs"},{"authors":null,"categories":null,"content":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Lecture  \u0026nbsp; 2019-01-21 \nKey Topics \u0026nbsp; ArcGIS Online \u0026nbsp; ArcGIS Pro\nResources \u0026nbsp; View on Syllabus  \u0026nbsp; View on GitHub  \u0026nbsp; Lab-01  \u0026nbsp; Lab-01 Replication \nVideos The following videos replicate the most important skills from Chapter 1 for the course.\nTutorial 1-1    Tutorial 1-2    Tutorial 1-3    Tutorial 1-4    Lab-01 Replication    Discussion Board Threads  Changes to the Labeling Interface  ","date":1516514400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548050400,"objectID":"57110bb2d6a00ac06d8ac138ce0cbf12","permalink":"/docs/lecture-02/","publishdate":"2018-01-21T00:00:00-06:00","relpermalink":"/docs/lecture-02/","section":"docs","summary":" Meta \u0026nbsp; Spring 2019  \u0026nbsp; Lecture  \u0026nbsp; 2019-01-21 \nKey Topics \u0026nbsp; ArcGIS Online \u0026nbsp; ArcGIS Pro\nResources \u0026nbsp; View on Syllabus  \u0026nbsp; View on GitHub  \u0026nbsp; Lab-01  \u0026nbsp; Lab-01 Replication \nVideos The following videos replicate the most important skills from Chapter 1 for the course.\nTutorial 1-1    Tutorial 1-2    Tutorial 1-3    Tutorial 1-4    Lab-01 Replication    Discussion Board Threads  Changes to the Labeling Interface  ","tags":null,"title":"Lecture-02 - ArcGIS Pro Overview","type":"docs"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483250400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483250400,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00-06:00","relpermalink":"/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461733200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461733200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00-05:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461733200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461733200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00-05:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461128400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515823200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00-05:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441083600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441083600,"objectID":"d77fa4a74076ffcd7ca6c21cfc27a4b2","permalink":"/publication/person-re-id/","publishdate":"2015-09-01T00:00:00-05:00","relpermalink":"/publication/person-re-id/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372654800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372654800,"objectID":"2b4d919e3cf73dfcd0063c88fe01cb00","permalink":"/publication/clothing-search/","publishdate":"2013-07-01T00:00:00-05:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]